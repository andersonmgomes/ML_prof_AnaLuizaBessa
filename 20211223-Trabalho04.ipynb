{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>3ª Atividade de Aprendizado de Máquina</center>\n",
    "# <center>Modelos Preditivos</center>\n",
    "### <center><b><i>Anderson Martins Gomes</i></b></center>\n",
    "## <center>Programa de Pós-graduação em Ciência da Computação - PPGCC/UECE</center>\n",
    "### <center><i>andersonmg@gmail.com</i></center>\n",
    "\n",
    "## <center><b>Resumo</b></center>\n",
    "<p style=\"margin-left: 50px; margin-right: 50px; text-align: justify\">Neste trabalho são realizados experimentos de redução de dimensionalidade com a base de dados <i>UCI Machine Learning Repository: Wine Quality Data Set</i>. Esse conjunto apresenta informações relacionadas à qualidade de vinhos brancos e tintos. Na análise, optou-se exclusivamente pelo subconjunto dos vinhos tintos. Nos testes implementou-se o algoritmo PCA, com o cálculo da matriz de covariância, dos autovalores, dos autovetores e da variância explicada. Além disso, foram realizados experimentos em três imagens, aplicando-se a redução de dimensionalidade em cada uma delas. Por fim, foi realizado um comparativo com outro algoritmo de redução de dimensionalidade, o LDA. Trabalho inserido no âmbito da disciplina de Aprendizado de Máquina, professora Ana Luiza Bessa, Programa de Pós-graduação em Ciência da Computação, Universidade Estadual do Ceará.</p>\n",
    "\n",
    "\n",
    "# <b>1. Introdução</b>\n",
    "<p style=\"text-align: justify; text-indent:50px;\">A denominada redução de dimensionalidade é técnica comumente aplicada em problemas que apresentam elevado número de atributos. É o caso clássico de aplicações de reconhecimento/processamento de imagens. O objetivo da técnica é representar o conjunto de dados com um menor número de variáveis, de forma a reduzir os custos computacionais e melhorar o desempenho do modelo induzido. Tal necessidade advém do problema da \"maldição da dimensionalidade\", que se trata justamente do aumento exponencial da variedade de objetos necessários ao treinamento a partir do número excessivo de variáveis independentes.\n",
    "</p>\n",
    "<p style=\"text-align: justify; text-indent:50px;\">\n",
    "O foco deste trabalho é um algoritmo de redução de dimensionalidade bastante popular, o <i>Principal Component Analysis</i>, mais conhecido pela sigla PCA. Sua implementação baseia-se na ideia de obter a correlação estatísticas das observações, reduzindo a dimensionalidade do conjunto de dados original por meio da combinação das variáveis originais.\n",
    "</p>\n",
    "<p style=\"text-align: justify; text-indent:50px;\">\n",
    "Conforme comandos das questões, buscou-se a implementação do PCA por meio do cálculo da matriz de covariância, dos autovalores, dos autovetores e da variância explicada. Além disso, foram realizados experimentos em três imagens, aplicando-se a redução de dimensionalidade em cada uma delas. Por fim, foi realizado um comparativo com outro algoritmo de redução de dimensionalidade, o LDA.\n",
    "</p>\n",
    "\n",
    "# <b>2. Redução de Dimensionalidade</b>\n",
    "<p style=\"text-align: justify; text-indent:50px;\">Redução de dimensionalidade é o processo por meio do qual se busca a transformação de um espaço para outro com menor dimensão, de forma a manter o valor intríseco dos dados o mais próximo possível do original. </p>\n",
    "<p style=\"text-align: justify; text-indent:50px;\">As técnicas para reduzir a dimensionalidade de modelos podem ser divididas em duas grandes categorias, a saber: agregação e seleção de atributos. Na primeira, ocorre a substituição de atributos, condensando-se mais de um deles em uma espécie de \"variável resumo\" que, com certo nível de perda, representa aquele conjunto de dados. Já a seleção de atributos se ocupa em identificar o sub-conjunto ótimo das variáveis independentes, de forma a eliminar <i>features</i> redundantes ou desnecessárias.\n",
    "</p>\n",
    "<p style=\"text-align: justify; text-indent:50px;\">A redução de dimensionalidade é importante para o aprendizado de máquina porque permite tornar \"tratáveis\" problemas envolvendo um grande espaço vetorial. Ou seja, torna mais viável computacionalmente a execução de um modelo quando este é substituído por outro com um menor número de variáveis.</p>\n",
    "\n",
    "# <b>3. PCA (Principal Component Analysis)</b>\n",
    "<p style=\"text-align: justify; text-indent:50px;\">O PCA é um método clássico de redução de dimensionalidade que provê uma sequência de melhores aproximações lineares do espaço de variáveis original. Assim, transforma um número de variáveis possivelmente correlacionadas em um novo sistema de coordenadas com um número menor de variáveis não correlacionadas chamadas componentes principais, enquanto mantém o tanto quanto possível da variabilidade nos dados originais.</p>\n",
    "<p style=\"text-align: justify; text-indent:50px;\">Para tal, calcula-se a matriz de correlação do conjunto de dados original. A partir dela, são decompostos os autovetores e os autovalores. Os autovetores dão as direções da nova base na qual a matriz de covariância é diagonal. Já os autovalores correspondem ao valor escalar que os autovetores correspondente são escalonados na transformação linear.</p>\n",
    "<p style=\"text-align: justify; text-indent:50px;\">Os autovalores dão a variância explicada do autovetor correspondente. Ordenando-se os autovetores em ordem descrescente de acordo\n",
    "com os autovalores, pode-se ordenar as components principais por ordem de importância, e eventualmente remover as associadas com uma variância pequena.</p>\n",
    "\n",
    "# <b>4. Variância Explicada</b>\n",
    "<p style=\"text-align: justify; text-indent:50px;\">O objetivo do PCA é obter a maior variância por meio do menor número de dimensões. Após a decomposição da matriz de correlação, tem-se na soma do autovalores ordenados a variância total dos autovetores correspondentes.</p>\n",
    "<p style=\"text-align: justify; text-indent:50px;\">Ou seja, variância explicada refere-se à medida da proporção na qual um modelo matemático contabiliza a variância de um dado conjunto de dados.</p>\n",
    "<p style=\"text-align: justify; text-indent:50px;\">Conforme essa proporção se aproxima de 100%, tem-se a possibilidade de selecionar as melhores dimensões, descartando-se as demais.</p>\n",
    "\n",
    "# <b>5. Método de Redução de Dimensionalidade para Comparação</b>\n",
    "<p style=\"text-align: justify; text-indent:50px;\">Para este trabalho, optou-se por se utilizar o LDA, Linear Discriminant Analysis, para fins de comparação com o PCA. O LDA é definido, na maioria das vezes, como um algoritmo de extração de <i>features</i> supervisionado. Todavia, alguns autores sustentam que o LDA pode ser utilizado como um classificador linear.</p>\n",
    "<p style=\"text-align: justify; text-indent:50px;\">Assim como o PCA, o LDA procura combinações lineares de variáveis que melhor explicam os dados. O LDA tenta explicitamente modelar a diferença entre as classes de dados. O PCA, por outro lado, não leva em consideração nenhuma diferença de classe, obtendo as combinações de recursos com base em diferenças em vez de semelhanças.</p>\n",
    "<p style=\"text-align: justify; text-indent:50px;\">O LDA sempre gera um número de <i>features</i> menor que o número de classes. Logo, em problemas de classificação binária o método gera apenas uma variável, independentemente do número de dimensões do <i>dataset</i> original.</p>\n",
    "\n",
    "# <b>6. Metodologia</b>\n",
    "<p style=\"text-align: justify; text-indent:50px;\">Para implementação dos experimentos, optou-se pela linguagem Python. Assim, foram utilizadas as bibliotecas bases da linguagem para o algoritmo PCA e o scikit-learn para comparação com o LDA. </p>\n",
    "\n",
    "# <b>7. Resultados</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-indent:50px;\">Carregando a base de dados e exibindo alguma informações básicas sobre o <i>dataset</i>:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1599 non-null   float64\n",
      " 1   volatile acidity      1599 non-null   float64\n",
      " 2   citric acid           1599 non-null   float64\n",
      " 3   residual sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free sulfur dioxide   1599 non-null   float64\n",
      " 6   total sulfur dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n"
     ]
    }
   ],
   "source": [
    "import ds_utils as util\n",
    "dsWineRed = util.getDSWine_RED()\n",
    "dsWineRed.info();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsWineRed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.319637</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>0.270976</td>\n",
       "      <td>2.538806</td>\n",
       "      <td>0.087467</td>\n",
       "      <td>15.874922</td>\n",
       "      <td>46.467792</td>\n",
       "      <td>0.996747</td>\n",
       "      <td>3.311113</td>\n",
       "      <td>0.658149</td>\n",
       "      <td>10.422983</td>\n",
       "      <td>5.636023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.741096</td>\n",
       "      <td>0.179060</td>\n",
       "      <td>0.194801</td>\n",
       "      <td>1.409928</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>10.460157</td>\n",
       "      <td>32.895324</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.169507</td>\n",
       "      <td>1.065668</td>\n",
       "      <td>0.807569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.996750</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    1599.000000       1599.000000  1599.000000     1599.000000   \n",
       "mean        8.319637          0.527821     0.270976        2.538806   \n",
       "std         1.741096          0.179060     0.194801        1.409928   \n",
       "min         4.600000          0.120000     0.000000        0.900000   \n",
       "25%         7.100000          0.390000     0.090000        1.900000   \n",
       "50%         7.900000          0.520000     0.260000        2.200000   \n",
       "75%         9.200000          0.640000     0.420000        2.600000   \n",
       "max        15.900000          1.580000     1.000000       15.500000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  1599.000000          1599.000000           1599.000000  1599.000000   \n",
       "mean      0.087467            15.874922             46.467792     0.996747   \n",
       "std       0.047065            10.460157             32.895324     0.001887   \n",
       "min       0.012000             1.000000              6.000000     0.990070   \n",
       "25%       0.070000             7.000000             22.000000     0.995600   \n",
       "50%       0.079000            14.000000             38.000000     0.996750   \n",
       "75%       0.090000            21.000000             62.000000     0.997835   \n",
       "max       0.611000            72.000000            289.000000     1.003690   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  1599.000000  1599.000000  1599.000000  1599.000000  \n",
       "mean      3.311113     0.658149    10.422983     5.636023  \n",
       "std       0.154386     0.169507     1.065668     0.807569  \n",
       "min       2.740000     0.330000     8.400000     3.000000  \n",
       "25%       3.210000     0.550000     9.500000     5.000000  \n",
       "50%       3.310000     0.620000    10.200000     6.000000  \n",
       "75%       3.400000     0.730000    11.100000     6.000000  \n",
       "max       4.010000     2.000000    14.900000     8.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsWineRed.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 1. Para a base de dados escolhida na Atividade 1, aplique redução de dimensionalidade utilizando a técnica PCA (Principal Component Analysis), e apresente:\n",
    "### • Matriz de covariância\n",
    "### • Autovalores da matriz de covariância\n",
    "### • Autovetores da matriz de covariância\n",
    "### • Variância explicada de acordo com a quantidade de autovetores\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset dimensions: (1599, 12)\n",
      "Dataset dimensions after drop NaN values: (1599, 12)\n",
      "ML problem type: Classification\n",
      "   Applied metrics: ['balanced_accuracy', 'f1_weighted', 'precision_weighted', 'recall_weighted', 'roc_auc_ovr_weighted']\n",
      "Normalizing the variables...\n",
      "Splitting dataset...\n",
      "   X_train dimensions: (1279, 11)\n",
      "Selected algorithms: ['KNeighborsClassifier']\n",
      "Nº of training possible combinations: 4094.0 (4094.0 features combinations, 1 algorithms)\n"
     ]
    }
   ],
   "source": [
    "from autoML import AutoML\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "ALGORITHMS = {\n",
    "    #classifiers\n",
    "    KNeighborsClassifier(n_jobs=-1):{\n",
    "        \"n_neighbors\": [3,11,17],\n",
    "        \"metric\": ['euclidean', 'manhattan', 'minkowski']\n",
    "        },\n",
    "    GaussianNB():{\n",
    "        \"priors\": [None],\n",
    "        },\n",
    "    MultinomialNB():{\n",
    "        \"alpha\": [1.0],\n",
    "        },\n",
    "    BernoulliNB():{\n",
    "        \"alpha\": [1.0],\n",
    "        },\n",
    "    DecisionTreeClassifier():{\n",
    "        \"criterion\": [\"gini\", \"entropy\"],\n",
    "        },\n",
    "    MLPClassifier():{\n",
    "        \"learning_rate\": ['constant', 'invscaling', 'adaptive'],\n",
    "        'momentum' : [0.1, 0.5, 0.9],\n",
    "        },        \n",
    "    SVC(probability=True):{\n",
    "        \"C\": [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "        \"gamma\": [\"auto\", \"scale\"],\n",
    "        \"kernel\": ['linear', 'rbf', 'poly'],\n",
    "        \"degree\": [2, 3, 4, 5],\n",
    "        },\n",
    "}\n",
    "\n",
    "ALGORITHMS = {\n",
    "    #classifiers\n",
    "    KNeighborsClassifier(n_jobs=-1):{\n",
    "        \"n_neighbors\": [3,11,17],\n",
    "        \"metric\": ['euclidean', 'manhattan', 'minkowski']\n",
    "        },\n",
    "}\n",
    "\n",
    "METRICS = ['accuracy', 'f1', 'precision', 'recall', 'roc_auc']\n",
    "\n",
    "automl = AutoML(dsWineRed, y_colname='quality', algorithms=ALGORITHMS, ds_name='espec_prof', metrics=METRICS, ngen=1, features_engineering=False)\n",
    "automl.getResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl.getBestConfusionMatrix();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2. Escolha três imagens de sua preferência e aplique redução de dimensionalidade a cada uma delas utilizando a técnica PCA (Principal Component Analysis). Para cada uma das imagens, apresente:\n",
    "### • Matriz de covariância\n",
    "### • Autovalores da matriz de covariância\n",
    "### • Autovetores da matriz de covariância\n",
    "### • Variância explicada de acordo com a quantidade de autovetores\n",
    "### • A imagem original e algumas versões com diferentes quantidades de autovetores\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3. Escolha um dos métodos de redução de dimensionalidade do artigo apresentado em sala de aula e faça uma comparação com a técnica PCA. Para basear sua análise, utilize, sempre que possível, os resultados obtidos nessa atividade.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Referências</b>\n",
    "* Mitchell, Tom. Machine learning. McGraw-Hill, 1997.\n",
    "* Carvalho, André, et al. Inteligência Artificial–uma abordagem de aprendizado de máquina. Rio de Janeiro: LTC, 2011.\n",
    "* Bruce, Andrew, and Peter Bruce. Estatística Prática para Cientistas de Dados. Alta Books, 2019.\n",
    "* https://en.wikipedia.org/wiki/Principal_component_analysis\n",
    "* https://en.wikipedia.org/wiki/Dimensionality_reduction\n",
    "* Ghodsi, Ali. Dimensionality Reduction A Short Tutorial. 2006.\n",
    "* R.A. Johnson. Applied Multivariate Statistical Analysis. Prentice Hall, 1992.\n",
    "* ANOWAR, Farzana, et al. Conceptual and empirical comparison of dimensionality reduction algorithms (PCA, KPCA, LDA, MDS, SVD, LLE, ISOMAP, LE, ICA, t-SNE). Computer Science Review, v. 40, p. 100378, 2021.\n",
    "* https://en.wikipedia.org/wiki/Linear_discriminant_analysis\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html\n",
    "* https://leandrocl2005.github.io/pca_na_mao_e_no_python/\n",
    "* https://scikit-learn.org/stable/auto_examples/neighbors/plot_nca_dim_reduction.html#sphx-glr-auto-examples-neighbors-plot-nca-dim-reduction-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext notexbook\n",
    "#%texify"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c4b62fceddc06dd276b407a252c1a463ef87e47b1a1840188fdb674abd87f8b3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
