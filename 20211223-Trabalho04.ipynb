{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>3ª Atividade de Aprendizado de Máquina</center>\n",
    "# <center>Modelos Preditivos</center>\n",
    "### <center><b><i>Anderson Martins Gomes</i></b></center>\n",
    "## <center>Programa de Pós-graduação em Ciência da Computação - PPGCC/UECE</center>\n",
    "### <center><i>andersonmg@gmail.com</i></center>\n",
    "\n",
    "## <center><b>Resumo</b></center>\n",
    "<p style=\"margin-left: 50px; margin-right: 50px; text-align: justify\">Neste trabalho são realizados experimentos para se comparar cinco modelos preditivos vistos na disciplina de Aprendizado de Máquina (KNN, Naive Bayes, Árvore de Decisão, MLP e SVM) e seus resultados na resolução de um problema de classificação. Para tal, será utilizada a base de dados <i>UCI Machine Learning Repository: Wine Quality Data Set</i>. Esse conjunto apresenta informações relacionadas à qualidade de vinhos brancos e tintos. Na análise, optou-se exclusivamente pelo subconjunto dos vinhos tintos, pretendo-se prever sua qualidade a partir das características disponíveis. Para a execução e comparação dos algoritmos, utilizou-se uma biblioteca de AutoML construída pelo aluno ao longo da disciplina (GOMES, 2021). Trabalho inserido no âmbito da disciplina de Aprendizado de Máquina, professora Ana Luiza Bessa, Programa de Pós-graduação em Ciência da Computação, Universidade Estadual do Ceará.</p>\n",
    "\n",
    "# <b>1. Introdução</b>\n",
    "\n",
    "<p style=\"text-align: justify; text-indent:50px;\">\n",
    "Problemas de aprendizado de máquina supervisionado são aqueles nos quais é possível prever uma variável alvo a partir de outras existentes no <i>dataset</i> de referência. As tarefas supervisionadas se distinguem pelo tipo dos rótulos dos dados: discreto, no caso de classificação; e contínuo, no caso de regressão (CARVALHO, 2011, p. 6).\n",
    "</p>\n",
    "<p style=\"text-align: justify; text-indent:50px;\">\n",
    "Este trabalho aborda um problema de aprendizado supervisionado, especificamente de classificação, uma vez que a variável alvo (<i>target</i>) é a qualidade dos vinhos (atributo 'quality'), cujos valores pertencem a um domínio discreto, conforme demonstrado abaixo:\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6, 7, 4, 8, 3], dtype=int64)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ds_utils as util\n",
    "dsWineRed = util.getDSWine_RED()\n",
    "dsWineRed['quality'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-indent:50px;\">\n",
    "Para a execução dos algoritmos e comparação dos resultados, utilizou-se uma biblioteca de AutoML construída pelo aluno ao longo da disciplina (GOMES, 2021). Em linhas gerais, a biblioteca encapsula as funções básicas de preparação do <i>dataset</i>, <i>features engineering</i> e otimização de hiper-parâmetros. \n",
    "</p>\n",
    "<p style=\"text-align: justify; text-indent:50px;\">\n",
    "Assim, a biblioteca se encarrega de executar as combinações entre o conjunto de features, o conjunto de algoritmos e de hiper-parâmetros, entregando os resultados conforme as métricas que forem definidas para o problema.\n",
    "</p>\n",
    "<p style=\"text-align: justify; text-indent:50px;\">\n",
    "Na seção pertinente serão detalhados alguns trechos principais da biblioteca de AutoML, importantes para o entendimento da resolução das questões.\n",
    "</p>\n",
    "\n",
    "# <b>2. Modelos Preditivos</b>\n",
    "<p style=\"text-align: justify; text-indent:50px;\">A seguir será realizada uma breve contextualização sobre os modelos preditivos selecionados para este trabalho.</p>\n",
    "## <b>2.1 KNN</b>\n",
    "<p style=\"text-align: justify; text-indent:50px;\"></p>\n",
    "## <b>2.2 Naive Bayes</b>\n",
    "<p style=\"text-align: justify; text-indent:50px;\"></p>\n",
    "## <b>2.3 Árvore de Decisão</b>\n",
    "<p style=\"text-align: justify; text-indent:50px;\"></p>\n",
    "## <b>2.4 MLP</b>\n",
    "<p style=\"text-align: justify; text-indent:50px;\"></p>\n",
    "## <b>2.5 SVM</b>\n",
    "<p style=\"text-align: justify; text-indent:50px;\"></p>\n",
    "\n",
    "# <b>3. Metodologia</b>\n",
    "<p style=\"text-align: justify; text-indent:50px;\">Como já explicitado na Introdução, para implementação dos experimentos, optou-se por encapsular em uma biblioteca própria, escrita em Python, as funcionalidades referentes às fases básicas de resolução de um problema de <i>Machine Learning</i>, quais sejam, o pré-processamento, a seleção de atributos, o treinamento do modelo, a otimização dos hiper-parâmetros e a obtenção dos resultados por meio das métricas de praxe.</p>\n",
    "<p style=\"text-align: justify; text-indent:50px;\">\n",
    "Seguindo o comando das questões, executou-se primeiramente a rotina de AutoML para o <i>dataset</i>, as <i>features</i>, os algoritmos e os hiper-parâmetros requeridos, utilizando-se o método de <i>GridSearch</i>, que é exaustivo, ou seja, testa todas as combinações de modelos possíveis.\n",
    "</p>\n",
    "<p style=\"text-align: justify; text-indent:50px;\">\n",
    "Em seguida, em uma nova leva de experimentos que objetivou o atingimento de melhores resultados, executou-se a biblioteca de AutoML em suas configurações padrão principais, quais sejam:<br/>\n",
    "- Inclusão de outros algoritmos de <i>Machine Learning</i>, incluindo métodos <i>ensemble</i>;<br/>\n",
    "- Uso de técnicas de Engenharia de Atributos para selecionar na fase de pré-processamento as <i>features</i> mais significativas;<br/>\n",
    "- Uso de algoritmo genético para seleção do sub-conjunto de algoritmo/<i>features</i> ótimo; <br/>\n",
    "- Uso de busca bayesiana com validação cruzada na seleção de hiper-parâmetros;<br/>\n",
    "</p>\n",
    "<p style=\"text-align: justify; text-indent:50px;\">\n",
    "Ao final, comparou-se os resultados em termos das métricas solicitadas no trabalho (Acurácia, Precisão, Recall, R-score e Curva ROC), além de se incluir análises relacionadas ao tempo para treinamento, tempo para predição e uso de memória.\n",
    "</p>\n",
    "\n",
    "# <b>4. Resultados</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-indent:50px;\">Carregando a base de dados e exibindo alguma informações básicas sobre o <i>dataset</i>:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1599 non-null   float64\n",
      " 1   volatile acidity      1599 non-null   float64\n",
      " 2   citric acid           1599 non-null   float64\n",
      " 3   residual sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free sulfur dioxide   1599 non-null   float64\n",
      " 6   total sulfur dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n"
     ]
    }
   ],
   "source": [
    "dsWineRed.info();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsWineRed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.319637</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>0.270976</td>\n",
       "      <td>2.538806</td>\n",
       "      <td>0.087467</td>\n",
       "      <td>15.874922</td>\n",
       "      <td>46.467792</td>\n",
       "      <td>0.996747</td>\n",
       "      <td>3.311113</td>\n",
       "      <td>0.658149</td>\n",
       "      <td>10.422983</td>\n",
       "      <td>5.636023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.741096</td>\n",
       "      <td>0.179060</td>\n",
       "      <td>0.194801</td>\n",
       "      <td>1.409928</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>10.460157</td>\n",
       "      <td>32.895324</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.169507</td>\n",
       "      <td>1.065668</td>\n",
       "      <td>0.807569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.996750</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    1599.000000       1599.000000  1599.000000     1599.000000   \n",
       "mean        8.319637          0.527821     0.270976        2.538806   \n",
       "std         1.741096          0.179060     0.194801        1.409928   \n",
       "min         4.600000          0.120000     0.000000        0.900000   \n",
       "25%         7.100000          0.390000     0.090000        1.900000   \n",
       "50%         7.900000          0.520000     0.260000        2.200000   \n",
       "75%         9.200000          0.640000     0.420000        2.600000   \n",
       "max        15.900000          1.580000     1.000000       15.500000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  1599.000000          1599.000000           1599.000000  1599.000000   \n",
       "mean      0.087467            15.874922             46.467792     0.996747   \n",
       "std       0.047065            10.460157             32.895324     0.001887   \n",
       "min       0.012000             1.000000              6.000000     0.990070   \n",
       "25%       0.070000             7.000000             22.000000     0.995600   \n",
       "50%       0.079000            14.000000             38.000000     0.996750   \n",
       "75%       0.090000            21.000000             62.000000     0.997835   \n",
       "max       0.611000            72.000000            289.000000     1.003690   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  1599.000000  1599.000000  1599.000000  1599.000000  \n",
       "mean      3.311113     0.658149    10.422983     5.636023  \n",
       "std       0.154386     0.169507     1.065668     0.807569  \n",
       "min       2.740000     0.330000     8.400000     3.000000  \n",
       "25%       3.210000     0.550000     9.500000     5.000000  \n",
       "50%       3.310000     0.620000    10.200000     6.000000  \n",
       "75%       3.400000     0.730000    11.100000     6.000000  \n",
       "max       4.010000     2.000000    14.900000     8.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsWineRed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoML import AutoML\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#Definição dos classificadores conforme especificação do trabalho\n",
    "#O formato de dicionário é o padrão requerido pela biblioteca AutoML.\n",
    "#Nele, temos a chave como o algoritmo classificador e o valor como um dicionário com as configurações dos hiper-parâmetros pertinentes.\n",
    "ALGORITHMS = {\n",
    "    KNeighborsClassifier:{\n",
    "        \"n_neighbors\": [3,11,17] #Utilizando três diferentes valores de K\n",
    "        , \"metric\": ['euclidean', 'manhattan', 'minkowski'] #Utilizando três diferentes métricas de distâncias\n",
    "        , \"n_jobs\": [-1] #Utilizando todas as possibilidades de número de jobs\n",
    "        },\n",
    "    GaussianNB:{ #Naive Bayes com distribuição gaussiana\n",
    "        \"priors\": [None], #Não há variação de parâmetros para este algoritmo\n",
    "        },\n",
    "    MultinomialNB:{ #Naive Bayes com distribuição multinomial\n",
    "        \"alpha\": [1.0], #Não há variação de parâmetros para este algoritmo\n",
    "        },\n",
    "    BernoulliNB:{ #Naive Bayes com distribuição Bernoulli\n",
    "        \"alpha\": [1.0], #Não há variação de parâmetros para este algoritmo\n",
    "        },\n",
    "    DecisionTreeClassifier:{\n",
    "        \"criterion\": [\"gini\", \"entropy\"], #Utilizando índice Gini e Entropia para o cálculo de qualidade da divisão dos nós\n",
    "        },\n",
    "    MLPClassifier:{\n",
    "        \"learning_rate\": ['constant', 'invscaling', 'adaptive'], #Utilizando diferentes valores de taxa de aprendizagem\n",
    "        'momentum' : [0.1, 0.5, 0.9], #Utilizando diferentes valores de momentum\n",
    "        },        \n",
    "    SVC:{\n",
    "        \"kernel\": ['linear', 'rbf', 'poly'], #Utilizando diferentes kernels\n",
    "        \"C\": [0.001, 1, 1000], #Utilizando diferentes valores de C\n",
    "        \"gamma\": [\"auto\", \"scale\"], #Utilizando diferentes valores de gamma\n",
    "        \"degree\": [1, 3, 5], #Utilizando diferentes valores de grau\n",
    "        \"probability\": [True] #Utilizando a probabilidade\n",
    "        },\n",
    "}\n",
    "\n",
    "METRICS = ['accuracy', 'f1', 'precision', 'recall', 'roc_auc'] #Definição das métricas utilizadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-indent:50px;\">\n",
    "Com os parâmetros básicos definidos, tem-se a criação do objeto de AutoML. Em sua instanciação já é executada uma série de operações de pré-processamento. As principais encontram-se detalhadas abaixo (para uma referência completa, ver (GOMES, 2021)):\n",
    "</p>\n",
    "\n",
    "<b>Exclusão de valores faltantes:</b>\n",
    "```python\n",
    "    print('Original dataset dimensions:', ds_source.shape)\n",
    "    #NaN values\n",
    "    ds = ds_source.dropna()\n",
    "    print('Dataset dimensions after drop NaN values:', ds.shape)\n",
    "    #shuffle data to minimize bias tendency\n",
    "    ds = ds.sample(frac=1)\n",
    "```\n",
    "<b>Processando o <i>target</i>, selecionando o tipo de problema e as métricas a serem utilizadas:</b>\n",
    "```python\n",
    "    #setting Y\n",
    "    self.y_colname = y_colname\n",
    "    self.y_full = ds[[self.y_colname]]\n",
    "    self.__y_encoder = None\n",
    "    self.y = np.asanyarray(self.y_full).reshape(-1, 1).ravel()\n",
    "    self.y_is_binary = False\n",
    "    self.y_classes = None\n",
    "    if self.YisCategorical():\n",
    "        print('ML problem type: Classification')\n",
    "        #encoding\n",
    "        self.__y_encoder = OrdinalEncoder(dtype=int)\n",
    "        self.y_full = pd.DataFrame(self.__y_encoder.fit_transform(self.y_full), columns=[self.y_colname])\n",
    "        self.y_classes = np.sort(self.y_full[self.y_colname].unique())\n",
    "        self.y_is_binary = len(self.y_classes) == 2\n",
    "        if not self.y_is_binary: #multiclass \n",
    "            #adjusting the metrics for multiclass target\n",
    "            for i, m in enumerate(self.metrics_classification_list):\n",
    "                if m == 'f1':\n",
    "                    self.metrics_classification_list[i] = 'f1_weighted'\n",
    "                elif m == 'roc_auc':\n",
    "                    self.metrics_classification_list[i] = 'roc_auc_ovr_weighted'\n",
    "                elif m == 'accuracy':\n",
    "                    self.metrics_classification_list[i] = 'balanced_accuracy'\n",
    "                elif m == 'recall':\n",
    "                    self.metrics_classification_list[i] = 'recall_weighted'\n",
    "                elif m == 'precision':\n",
    "                    self.metrics_classification_list[i] = 'precision_weighted'\n",
    "    else:\n",
    "        print('ML problem type: Regression')\n",
    "\n",
    "    print('   Applied metrics:', self.metrics_classification_list)\n",
    "```  \n",
    "<b>Processando as <i>features</i> e transformando as variáveis categóricas por meio da técnica de <i>One Hot Encoder</i>:</b>\n",
    "```python\n",
    "    #setting X\n",
    "    self.X = ds.drop(self.y_colname, axis=1)\n",
    "    self.__onehot_encoder = OneHotEncoder(sparse=False, dtype=int)\n",
    "\n",
    "    hot_columns = []\n",
    "    str_columns = []\n",
    "    for i, col in enumerate(self.X.columns):\n",
    "        if self.X.dtypes[i] == object: \n",
    "            if len(self.X[col].unique()) <= self.__unique_categoric_limit:\n",
    "                hot_columns.append(col)\n",
    "            else:\n",
    "                str_columns.append(col)\n",
    "    \n",
    "    if len(str_columns) > 0:\n",
    "        self.X = self.X.drop(str_columns, axis=1)\n",
    "        \n",
    "    if len(hot_columns) > 0:\n",
    "        print('One hot encoder columns:', hot_columns)\n",
    "        self.__onehot_encoder.fit(self.X[hot_columns])\n",
    "        \n",
    "        hot_cols_names = []\n",
    "        \n",
    "        for i, name in enumerate(self.__onehot_encoder.feature_names_in_):\n",
    "            for cat in self.__onehot_encoder.categories_[i]:\n",
    "                hot_cols_names.append(name + '_' + cat.lower().replace(' ','_'))\n",
    "                \n",
    "        self.X = pd.concat([self.X.drop(hot_columns, axis=1)\n",
    "                            , pd.DataFrame(self.__onehot_encoder.transform(self.X[hot_columns])\n",
    "                                        , columns=hot_cols_names)], axis=1)\n",
    "```  \n",
    "<b>Normalizando o <i>X</i> e dividindo o <i>dataset</i> em porções de treino e teste:</b>\n",
    "```python\n",
    "    #normalizing the variables\n",
    "    print('Normalizing the variables...')\n",
    "    self.scaler = preprocessing.MinMaxScaler()\n",
    "    self.X = pd.DataFrame(self.scaler.fit_transform(self.X), columns=self.X.columns) \n",
    "\n",
    "    #splitting dataset\n",
    "    print('Splitting dataset...')\n",
    "    self.X_train, self.X_test, self.y_train, self.y_test = self.__train_test_split()\n",
    "    print('   X_train dimensions:', self.X_train.shape)\n",
    "    self.y_train = np.asanyarray(self.y_train).reshape(-1, 1).ravel()\n",
    "    self.y_test = np.asanyarray(self.y_test).reshape(-1, 1).ravel()\n",
    "```  \n",
    "<b>Realizando o <i>features engineering</i>, caso o AutoML tenha sido configurado para isto.</b> \n",
    "<p style=\"text-align: justify; text-indent:50px;\">\n",
    "São realizados dois tipos de processamento. No primeiro compara-se a correlação de cada feature com o Y. Caso não esteja acima de um determinado limite (variável <i>self.__min_x_y_correlation_rate</i>), a coluna é descartada. Na outra abordagem, testa-se cada variável com as outras. Caso a correlação esteja acima de um determinado nível (1 - o valor da variável <i>self.__min_x_y_correlation_rate</i>), considera-se as <i>features</i> redundantes, excluindo-se uma delas.\n",
    "</p>\n",
    "\n",
    "```python\n",
    "\n",
    "    def features_corr_level_Y(i, X, y, threshold):\n",
    "        #features engineering\n",
    "        #testing correlation between X and Y\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            corr = sta.pearsonr(X, y)[0]\n",
    "        if ( (corr != corr) #NaN value for correlation because constant feature\n",
    "            or (abs(corr) < threshold)\n",
    "            ):\n",
    "            return None#x[i] below the threshold\n",
    "        #else: feature ok with Y\n",
    "        return i\n",
    "\n",
    "    def features_corr_level_X(i, X_0, X_i, threshold):\n",
    "        #features engineering\n",
    "        #testing correlation between X_0 and X_i\n",
    "        for i in range(0, X_i.shape[1]):\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                corr = sta.pearsonr(X_0, X_i.iloc[:,i])[0]\n",
    "            if ( (corr != corr) #NaN value for correlation because constant feature\n",
    "                or (abs(corr) > threshold)\n",
    "                ):\n",
    "                return None#x[i] above the threshold\n",
    "        #else: feature ok, no redundance\n",
    "        return i\n",
    "\n",
    "    #running feature engineering in paralel\n",
    "    if features_engineering:\n",
    "        n_cols = self.X_train.shape[1]\n",
    "        print('Features engineering - Testing correlation with Y...')\n",
    "        considered_features = Parallel(n_jobs=-1, backend=\"multiprocessing\")(delayed(features_corr_level_Y)\n",
    "                                (i\n",
    "                                , self.X_train.iloc[:,i]\n",
    "                                , self.y_train\n",
    "                                , self.__min_x_y_correlation_rate)\n",
    "                                for i in range(0, n_cols))\n",
    "        considered_features = [x for x in considered_features if x is not None]\n",
    "        self.X_train = self.X_train.iloc[:,considered_features]\n",
    "        self.X_test = self.X_test.iloc[:,considered_features]\n",
    "        \n",
    "        def n_features_2str():\n",
    "            return \"{:.2f}\".format(100*(1-len(considered_features)/self.X.shape[1])) + \"% (\" + str(len(considered_features)) + \" remained)\"\n",
    "        \n",
    "        print('   Features engineering - Features reduction after correlation test with Y:'\n",
    "            , n_features_2str())\n",
    "        \n",
    "        print('Features engineering - Testing redudance between features...')    \n",
    "        \n",
    "        n_cols = self.X_train.shape[1]\n",
    "        considered_features = Parallel(n_jobs=-1, backend=\"multiprocessing\")(delayed(features_corr_level_X)\n",
    "                                (i\n",
    "                                ,self.X_train.iloc[:,i]\n",
    "                                , self.X_train.iloc[:,i+1:]\n",
    "                                , (1-self.__min_x_y_correlation_rate))\n",
    "                                for i in range(0, n_cols-1))\n",
    "\n",
    "        considered_features = [x for x in considered_features if x is not None]\n",
    "        self.X_train = self.X_train.iloc[:,considered_features]\n",
    "        self.X_test = self.X_test.iloc[:,considered_features]\n",
    "        \n",
    "        print('   Features engineering - Features reduction after redudance test:'\n",
    "            , n_features_2str())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset dimensions: (1599, 12)\n",
      "Dataset dimensions after drop NaN values: (1599, 12)\n",
      "ML problem type: Classification\n",
      "   Applied metrics: ['balanced_accuracy', 'f1_weighted', 'precision_weighted', 'recall_weighted', 'roc_auc_ovr_weighted']\n",
      "Normalizing the variables...\n",
      "Splitting dataset...\n",
      "   X_train dimensions: (1279, 11)\n"
     ]
    }
   ],
   "source": [
    "#Definição do objeto AutoML\n",
    "automl = AutoML(dsWineRed\n",
    "                , y_colname='quality' \n",
    "                , algorithms=ALGORITHMS\n",
    "                , ds_name='experimento_1'\n",
    "                , metrics=METRICS\n",
    "                , ngen=1 #Número de gerações do algoritmo genético que otimiza a busca pela melhor combinação de features/algoritmos\n",
    "                , features_engineering=False #Não fazer features engineering (usará todas as features do dataset)\n",
    "                , grid_search=True #Utilizar grid search em vez de Bayesian optimization\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-indent:50px;\">\n",
    "Segue-se para o treinamento propriamento dito (usando algoritmo genético) e a exibição da tabela comparativa de resultados. Abaixo reprodução dos principais trechos seguido da execução do método \"getResults()\".\n",
    "</p>\n",
    "\n",
    "<b>Função <i>fitness</i> do algoritmo genético:</b>\n",
    "\n",
    "```python\n",
    "\n",
    "def evaluation(individual, automl_obj):\n",
    "    def float2bigint(float_value):\n",
    "        if math.isnan(float_value):\n",
    "            float_value = -1\n",
    "        return [int(float_value*100000)]\n",
    "    \n",
    "    #print(individual)\n",
    "    \n",
    "    algo = individual[-automl_obj.n_bits_algos:]\n",
    "    algo = bautil.ba2int(bitarray(algo)) % len(automl_obj.selected_algos)\n",
    "    \n",
    "    algo = automl_obj.selected_algos[algo]\n",
    "    \n",
    "    col_tuple = individual[:len(automl_obj.X_bitmap)-automl_obj.n_bits_algos]\n",
    "    col_tuple = tuple([automl_obj.X_train.columns[i] for i, c in enumerate(col_tuple) if c == 1])\n",
    "    \n",
    "    if len(col_tuple)==0:\n",
    "        return float2bigint(-1)\n",
    "    \n",
    "    def is_ensemble(a):\n",
    "        return isinstance(a, VotingClassifier) or isinstance(a, StackingClassifier)\n",
    "    \n",
    "    if is_ensemble(algo):\n",
    "        #getting the top 3 best results group by algorithm\n",
    "        best_estimators = []\n",
    "        automl_obj.results.sort_values(by=automl_obj.main_metric, ascending=False, inplace=True)\n",
    "        for row in automl_obj.results.iterrows():\n",
    "            if len(best_estimators)==3:\n",
    "                break\n",
    "            candidate_algo = row[1]['algorithm']\n",
    "            if ((candidate_algo not in best_estimators)\n",
    "                and (not is_ensemble(candidate_algo))):\n",
    "                best_estimators.append(candidate_algo)\n",
    "        algo.estimators = list(zip(['e'+str(i) for i in range(1,len(best_estimators)+1)],best_estimators))\n",
    "        \n",
    "    X_train2 = automl_obj.X_train[list(col_tuple)]\n",
    "    X_test2 = automl_obj.X_test[list(col_tuple)]\n",
    "    \n",
    "    if len(col_tuple)==1:\n",
    "        X_train2 = np.asanyarray(X_train2).reshape(-1, 1)\n",
    "        X_test2 = np.asanyarray(X_test2).reshape(-1, 1)\n",
    "\n",
    "    scoring_list = automl_obj.getMetrics()\n",
    "    \n",
    "    #tunning parameters\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        if automl_obj.grid_search:\n",
    "            opt = GridSearchCV(estimator=algo, param_grid=automl_obj.algorithms[algo]\n",
    "                                , scoring=automl_obj.main_metric\n",
    "                                , cv=5\n",
    "                                , verbose=0, n_jobs=-1\n",
    "                                )\n",
    "        else:\n",
    "            opt = BayesSearchCV(estimator=algo, search_spaces=automl_obj.algorithms[algo]\n",
    "                                , scoring=automl_obj.main_metric\n",
    "                                , n_iter=30, cv=5\n",
    "                                , verbose=0, n_jobs=-1, random_state=automl_obj.RANDOM_STATE\n",
    "                                )\n",
    "        opt.fit(X_train2, automl_obj.y_train)\n",
    "\n",
    "    def fit_score():\n",
    "        estimator = algo.set_params(**params)\n",
    "        row = {'algorithm': estimator\n",
    "               , 'params': params\n",
    "               , 'features': col_tuple\n",
    "               , 'n_features': len(col_tuple)\n",
    "               }\n",
    "\n",
    "        t0 = time.perf_counter()\n",
    "        estimator.fit(X_train2, automl_obj.y_train)\n",
    "        row['train_time'] = time.perf_counter() - t0 #train_time\n",
    "        \n",
    "        t0 = time.perf_counter()\n",
    "        \n",
    "        for scor_str in scoring_list:\n",
    "            row[scor_str] = (get_scorer(scor_str)(estimator, X_test2, automl_obj.y_test))\n",
    "        \n",
    "        row['predict_time'] = (time.perf_counter() - t0)/len(automl_obj.y_test) #predict_time, considering one sample at a time\n",
    "        \n",
    "        if automl_obj.YisCategorical():\n",
    "            #confusion matrix\n",
    "            row['confusion_matrix'] = confusion_matrix(automl_obj.y_test, estimator.predict(X_test2), labels=automl_obj.y_classes)\n",
    "        \n",
    "        return row\n",
    "        \n",
    "    best_score = -1.0\n",
    "    #dataframe format: ['algorithm', 'params', 'features', 'n_features', 'train_time', 'predict_time', 'mem_max', <metrics>]\n",
    "    for params in opt.cv_results_['params']:\n",
    "        #seeking for some previous result\n",
    "        previous_result = automl_obj.results[(automl_obj.results['algorithm'] == algo) \n",
    "                                             & (automl_obj.results['params'] == params)\n",
    "                                            & (automl_obj.results['features'] == col_tuple)]\n",
    "        if previous_result.shape[0]>0:\n",
    "            continue\n",
    "        #else \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            mem_max, row_result = memory_usage(proc=(fit_score)\n",
    "                                                , max_usage=True\n",
    "                                                , retval=True\n",
    "                                                , include_children=True)\n",
    "        row_result['mem_max'] = mem_max\n",
    "\n",
    "        automl_obj.results.loc[len(automl_obj.results)] = row_result\n",
    "\n",
    "        if row_result[automl_obj.main_metric] > best_score:\n",
    "            best_score = row_result[automl_obj.main_metric]\n",
    "            \n",
    "        log_msg = '   *Model trained: ' + str(scoring_list[0]) \n",
    "        log_msg += ' = {:.5f}'.format(row_result[automl_obj.main_metric]) \n",
    "        log_msg += ' | ' + str(algo)[:str(algo).find('(')] \n",
    "        log_msg += ' | ' + str(len(col_tuple)) + ' features' \n",
    "        log_msg += ' | ' + str(params)[str(params).find('[')+1:str(params).find(']')]\n",
    "\n",
    "        print(log_msg[:150].replace('\\n',''))#show only the 150 first caracteres\n",
    " \n",
    "    flushResults(automl_obj)\n",
    "    return float2bigint(best_score) #main metric\n",
    "```\n",
    "\n",
    "<b>Função que configura a primeira geração para o algoritmo genético, forçando que todas as <i>features</i> sejam utilizadas na primeira rodada:</b>\n",
    "\n",
    "```python\n",
    "def gen_first_people(n_features, n_algos, n_bits_algos):\n",
    "    first_people = []\n",
    "    X_bitmap = bautil.int2ba(1, n_features)\n",
    "    X_bitmap.setall(1)\n",
    "    for i in range(n_algos):\n",
    "        c_bitmap = []\n",
    "        c_bitmap.extend(list(X_bitmap))\n",
    "        c_bitmap.extend(list(bautil.int2ba(i, n_bits_algos)))\n",
    "        first_people.append(c_bitmap)\n",
    "    return first_people\n",
    "```\n",
    "<b>Função de configuração do algoritmo genético:</b>\n",
    "\n",
    "```python\n",
    "def ga_toolbox(automl_obj):\n",
    "    #genetics algorithm: creating types\n",
    "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "    #multiprocessing\n",
    "    toolbox = base.Toolbox()\n",
    "    if not(automl_obj.pool is None):\n",
    "        #toolbox.register(\"map\", pool.map) #TODO: check if it works\n",
    "        pass\n",
    "\n",
    "    #genetics algorithm: initialization\n",
    "    def initPopulation(pcls, ind_init):\n",
    "        return pcls(ind_init(c) for c in gen_first_people(automl_obj.X_train.shape[1], len(automl_obj.selected_algos), automl_obj.n_bits_algos))\n",
    "    toolbox.register(\"population\", initPopulation, list, creator.Individual)\n",
    "    \n",
    "    #genetics algorithm: operators\n",
    "    toolbox.register(\"evaluate\", evaluation, automl_obj=automl_obj)\n",
    "    toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "    toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.1)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "    return toolbox\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected algorithms: ['KNeighborsClassifier', 'GaussianNB', 'MultinomialNB', 'BernoulliNB', 'DecisionTreeClassifier', 'MLPClassifier', 'SVC']\n",
      "Nº of training possible basic combinations: 28658.0 (4094.0 features combinations, 7 algorithms)\n",
      "   *Model trained: balanced_accuracy = 0.27436 | KNeighborsClassifier | 11 features | {'metric': 'euclidean', 'n_neighbors': 3\n",
      "   *Model trained: balanced_accuracy = 0.29770 | KNeighborsClassifier | 11 features | {'metric': 'euclidean', 'n_neighbors': 11\n",
      "   *Model trained: balanced_accuracy = 0.29338 | KNeighborsClassifier | 11 features | {'metric': 'euclidean', 'n_neighbors': 17\n",
      "   *Model trained: balanced_accuracy = 0.28457 | KNeighborsClassifier | 11 features | {'metric': 'manhattan', 'n_neighbors': 3\n",
      "   *Model trained: balanced_accuracy = 0.28539 | KNeighborsClassifier | 11 features | {'metric': 'manhattan', 'n_neighbors': 11\n",
      "   *Model trained: balanced_accuracy = 0.28528 | KNeighborsClassifier | 11 features | {'metric': 'manhattan', 'n_neighbors': 17\n",
      "   *Model trained: balanced_accuracy = 0.27436 | KNeighborsClassifier | 11 features | {'metric': 'minkowski', 'n_neighbors': 3\n",
      "   *Model trained: balanced_accuracy = 0.29770 | KNeighborsClassifier | 11 features | {'metric': 'minkowski', 'n_neighbors': 11\n",
      "   *Model trained: balanced_accuracy = 0.29338 | KNeighborsClassifier | 11 features | {'metric': 'minkowski', 'n_neighbors': 17\n",
      "   *Model trained: balanced_accuracy = 0.44313 | GaussianNB | 11 features | {'priors': None\n",
      "   *Model trained: balanced_accuracy = 0.20182 | MultinomialNB | 11 features | {'alpha': 1.0\n",
      "   *Model trained: balanced_accuracy = 0.17083 | BernoulliNB | 11 features | {'alpha': 1.0\n",
      "   *Model trained: balanced_accuracy = 0.37990 | DecisionTreeClassifier | 11 features | {'criterion': 'gini'\n",
      "   *Model trained: balanced_accuracy = 0.30788 | DecisionTreeClassifier | 11 features | {'criterion': 'entropy'\n",
      "   *Model trained: balanced_accuracy = 0.30594 | MLPClassifier | 11 features | {'learning_rate': 'constant', 'momentum': 0.1\n",
      "   *Model trained: balanced_accuracy = 0.28675 | MLPClassifier | 11 features | {'learning_rate': 'constant', 'momentum': 0.5\n",
      "   *Model trained: balanced_accuracy = 0.28552 | MLPClassifier | 11 features | {'learning_rate': 'constant', 'momentum': 0.9\n",
      "   *Model trained: balanced_accuracy = 0.28555 | MLPClassifier | 11 features | {'learning_rate': 'invscaling', 'momentum': 0.1\n",
      "   *Model trained: balanced_accuracy = 0.29534 | MLPClassifier | 11 features | {'learning_rate': 'invscaling', 'momentum': 0.5\n",
      "   *Model trained: balanced_accuracy = 0.28813 | MLPClassifier | 11 features | {'learning_rate': 'invscaling', 'momentum': 0.9\n",
      "   *Model trained: balanced_accuracy = 0.28969 | MLPClassifier | 11 features | {'learning_rate': 'adaptive', 'momentum': 0.1\n",
      "   *Model trained: balanced_accuracy = 0.28709 | MLPClassifier | 11 features | {'learning_rate': 'adaptive', 'momentum': 0.5\n",
      "   *Model trained: balanced_accuracy = 0.28698 | MLPClassifier | 11 features | {'learning_rate': 'adaptive', 'momentum': 0.9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8512/2659242842.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mautoml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetResults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\automl\\autoML.py\u001b[0m in \u001b[0;36mgetResults\u001b[1;34m(self, buffer)\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgetResults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 559\u001b[1;33m         \u001b[0mresults_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'confusion_matrix'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'n_features'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    560\u001b[0m         \u001b[0mresults_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'algorithm'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'algorithm'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class2str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m         \u001b[0mresults_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'features'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'features'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'('\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m')'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\automl\\autoML.py\u001b[0m in \u001b[0;36m__fit\u001b[1;34m(self, buffer)\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[0mtoolbox\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mga_toolbox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[1;31m#running the GA algorithm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 633\u001b[1;33m         \u001b[0malgorithms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meaSimple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoolbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcxpb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmutpb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mngen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mngen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    634\u001b[0m         \u001b[1;31m#free GA memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m         \u001b[1;32mdel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoolbox\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\deap\\algorithms.py\u001b[0m in \u001b[0;36meaSimple\u001b[1;34m(population, toolbox, cxpb, mutpb, ngen, stats, halloffame, verbose)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[0minvalid_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpopulation\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[0mfitnesses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoolbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minvalid_ind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minvalid_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfitnesses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m         \u001b[0mind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\automl\\autoML.py\u001b[0m in \u001b[0;36mevaluation\u001b[1;34m(individual, automl_obj)\u001b[0m\n\u001b[0;32m    161\u001b[0m                                 \u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mautoml_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRANDOM_STATE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m                                 )\n\u001b[1;32m--> 163\u001b[1;33m         \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mautoml_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1392\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    836\u001b[0m                     )\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 838\u001b[1;33m                 out = parallel(\n\u001b[0m\u001b[0;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[0;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    936\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    433\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "automl.getResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl.getBestConfusionMatrix();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-indent:50px;\">\n",
    "Executando novo experimento, agora com as configurações do AutoML permitindo o uso de outros algoritmos (16 no total), incluindo <i>ensembles</i>, e com inúmeras configurações de hiper-parâmetros otimizados por meio do método BayesSearchCV. Além disso, habilitou-se o recurso de engenharia de atributos e se configurou o algoritmo genético com o limite de apenas 5 gerações, considerando a alta exigência computacional. \n",
    "</p>\n",
    "\n",
    "<p style=\"text-align: justify; text-indent:50px;\">\n",
    "Abaixo o trecho de código da biblioteca de AutoML que define os algoritmos e o espaço de busca dos hiper-parâmetros:\n",
    "</p>\n",
    "\n",
    "```python\n",
    "class AutoML:\n",
    "    ALGORITHMS = {\n",
    "        #classifiers\n",
    "        #https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
    "        KNeighborsClassifier(n_jobs=-1): \n",
    "            {\"n_neighbors\": [3,5,7,9,11,13,15,17],\n",
    "             \"p\": [2, 3],\n",
    "             },\n",
    "        SVC(probability=True):\n",
    "            {\"C\": [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "             \"gamma\": [\"auto\", \"scale\"],\n",
    "             \"class_weight\": [\"balanced\", None]},\n",
    "        GaussianProcessClassifier(n_jobs=-1):{\n",
    "            \"copy_X_train\": [False],\n",
    "            \"warm_start\": [True, False],},\n",
    "        DecisionTreeClassifier():{\n",
    "            \"criterion\": [\"gini\", \"entropy\"],\n",
    "            },\n",
    "        RandomForestClassifier(n_jobs=-1):{\n",
    "            \"n_estimators\": [120,300,500,800,1200],\n",
    "            \"max_depth\": [None, 5, 8, 15, 20, 25, 30],\n",
    "            \"min_samples_split\": [2, 5, 10, 15, 100],\n",
    "            \"min_samples_leaf\": [1, 2, 5, 10],\n",
    "            \"max_features\": [None, \"sqrt\", \"log2\"],\n",
    "            },\n",
    "        MLPClassifier():{\n",
    "            \"learning_rate\": ['constant', 'invscaling', 'adaptive'], \n",
    "            'momentum' : [0.1, 0.5, 0.9], \n",
    "            },\n",
    "        AdaBoostClassifier():{\n",
    "            \"algorithm\": [\"SAMME\", \"SAMME.R\"],\n",
    "            },\n",
    "        GaussianNB():{\n",
    "            \"priors\": [None],\n",
    "            },\n",
    "        QuadraticDiscriminantAnalysis():{\n",
    "            \"priors\": [None],\n",
    "            },\n",
    "        XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'):{\n",
    "            \"eta\": [0.01, 0.015, 0.025, 0.05, 0.1],\n",
    "            \"gamma\": [0.05, 0.1, 0.3, 0.5, 0.7, 0.9, 1],\n",
    "            \"max_depth\": [3, 5, 7, 9, 12, 15, 17, 25],\n",
    "            \"min_child_weight\": [1, 3, 5, 7],\n",
    "            \"subsample\": [0.6, 0.7, 0.8, 0.9, 1],\n",
    "            \"colsample_bytree\": [0.6, 0.7, 0.8, 0.9, 1],\n",
    "            \"lambda\": [0.01,0.1,1],\n",
    "            \"alpha\": [0, 0.1, 0.5, 1],\n",
    "            },\n",
    "        MultinomialNB():{\n",
    "            \"fit_prior\": [True, False],\n",
    "            }, \n",
    "        GradientBoostingClassifier():{\n",
    "            \"loss\": [\"deviance\"],\n",
    "            },\n",
    "        HistGradientBoostingClassifier():{\n",
    "            \"warm_start\": [True, False],\n",
    "            },\n",
    "        #TPOTClassifier(verbosity=0, n_jobs=-1):{},\n",
    "        linear_model.LinearRegression(n_jobs=-1):{\n",
    "            \"fit_intercept\": [True, False],\n",
    "            },\n",
    "        linear_model.LogisticRegression(n_jobs=-1):{\n",
    "            \"C\": [0.001, 0.01, 0.1, 1, 10,\n",
    "                  100, 1000],\n",
    "            },\n",
    "        VotingClassifier(estimators=[], n_jobs=-1):{\n",
    "            \"voting\": [\"soft\"],\n",
    "            },\n",
    "        StackingClassifier(estimators=[], n_jobs=-1):{\n",
    "            \"stack_method\": [\"auto\"],\n",
    "            },\n",
    "        #regressors        \n",
    "        XGBRegressor():{},\n",
    "        XGBRFRegressor():{},\n",
    "        svm.SVR():{},\n",
    "        tree.DecisionTreeRegressor():{},\n",
    "        neighbors.KNeighborsRegressor():{},\n",
    "        GradientBoostingRegressor():{},    \n",
    "    }  \n",
    "```    \n",
    "\n",
    "<p style=\"text-align: justify; text-indent:50px;\">\n",
    "Construtor da classe com as configurações padrão:\n",
    "</p>\n",
    "\n",
    "```python\n",
    "    def __init__(self, ds_source, y_colname = 'y'\n",
    "                 , algorithms = ALGORITHMS\n",
    "                 , unique_categoric_limit = 10 \n",
    "                 , min_x_y_correlation_rate = 0.01\n",
    "                 , pool = None\n",
    "                 , ds_name = None\n",
    "                 , ngen = 10\n",
    "                 , metrics = None\n",
    "                 , features_engineering = True\n",
    "                 , grid_search = False\n",
    "                 ) -> None:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl2 = AutoML(dsWineRed\n",
    "                , y_colname='quality' \n",
    "                , ds_name='experimento_2'\n",
    "                , metrics=METRICS #mesmas métricas definidas originalmente para o experimento 1\n",
    "                , ngen=5 #Número de gerações do algoritmo genético que otimiza a busca pela melhor combinação de features/algoritmos\n",
    "                , n_inter_bayessearch=10 #Número de iterações do Bayesian optimization\n",
    "                )\n",
    "automl2.getResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl2.getBestConfusionMatrix();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# desbalanceamento do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_classes = dsWineRed.quality.value_counts().sort_index()\n",
    "# Mostra gráfico a dirtibuição de amostras por rótulo da variável dependente(\"target\")\n",
    "dist_classes.plot(xlabel='Quality', ylabel='total de amostras'\n",
    "                              , kind='bar',title='Total de amostras por nota de qualidade');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "# Atribuir valores para X e y\n",
    "X = dsWineRed.iloc[:,:-1]\n",
    "y = dsWineRed.quality\n",
    "\n",
    "# Mostrar as dimensões de X e y\n",
    "print('Dimensões de X = ', X.shape)\n",
    "print('Dimensões de y = ', y.shape)\n",
    "\n",
    "over = RandomOverSampler(random_state=0)\n",
    "\n",
    "X_resampled, y_resampled = over.fit_resample(X, y)\n",
    "\n",
    "# Mostrar as dimensões de X e y\n",
    "print('Dimensões de X_resampled = ', X_resampled.shape)\n",
    "print('Dimensões de y_resampled = ', y_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_oversampled = pd.DataFrame(X_resampled)\n",
    "df_oversampled['target']= y_resampled\n",
    "df_oversampled.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra gráfico a distribuição de amostras por rótulo da variável dependente(\"target\")\n",
    "df_oversampled.target.value_counts().plot(xlabel='Nota', ylabel='total de amostras'\n",
    "                              , kind='bar',title='Total de amostras por nota de qualidade');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl3 = AutoML(df_oversampled\n",
    "                , y_colname='target' \n",
    "                , ds_name='experimento_3'\n",
    "                , metrics=METRICS #mesmas métricas definidas originalmente para o experimento 1\n",
    "                , ngen=5 #Número de gerações do algoritmo genético que otimiza a busca pela melhor combinação de features/algoritmos\n",
    "                , n_inter_bayessearch=10 #Número de iterações do Bayesian optimization\n",
    "                )\n",
    "automl3.getResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl3.getBestConfusionMatrix();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>5. Comparação entre os modelos</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3. Escolha um dos métodos de redução de dimensionalidade do artigo apresentado em sala de aula e faça uma comparação com a técnica PCA. Para basear sua análise, utilize, sempre que possível, os resultados obtidos nessa ati\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Referências</b>\n",
    "* GOMES, A.M. <b>Experimental Automl library, which uses genetic algorithm, multiprocessing and hyper-parameter optimization to solve supervised learning problems</b>. Disponível em <https://github.com/andersonmgomes/automl>. Acesso em: 20 dez. 2021.\n",
    "* Mitchell, Tom. Machine learning. McGraw-Hill, 1997.\n",
    "* CARVALHO, André, et al. Inteligência Artificial–uma abordagem de aprendizado de máquina. Rio de Janeiro: LTC, 2011.\n",
    "* Bruce, Andrew, and Peter Bruce. Estatística Prática para Cientistas de Dados. Alta Books, 2019.\n",
    "* https://en.wikipedia.org/wiki/Principal_component_analysis\n",
    "* https://en.wikipedia.org/wiki/Dimensionality_reduction\n",
    "* Ghodsi, Ali. Dimensionality Reduction A Short Tutorial. 2006.\n",
    "* R.A. Johnson. Applied Multivariate Statistical Analysis. Prentice Hall, 1992.\n",
    "* ANOWAR, Farzana, et al. Conceptual and empirical comparison of dimensionality reduction algorithms (PCA, KPCA, LDA, MDS, SVD, LLE, ISOMAP, LE, ICA, t-SNE). Computer Science Review, v. 40, p. 100378, 2021.\n",
    "* https://en.wikipedia.org/wiki/Linear_discriminant_analysis\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html\n",
    "* https://leandrocl2005.github.io/pca_na_mao_e_no_python/\n",
    "* https://scikit-learn.org/stable/auto_examples/neighbors/plot_nca_dim_reduction.html#sphx-glr-auto-examples-neighbors-plot-nca-dim-reduction-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext notexbook\n",
    "#%texify"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c4b62fceddc06dd276b407a252c1a463ef87e47b1a1840188fdb674abd87f8b3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
